{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = ('./amazon_cells_labelled.txt')\n",
    "sentiment_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sentiment_raw.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_df = sentiment_raw.copy() # make the first copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = ['do not', 'no problem', 'the best', 'loved it','the best', 'the greatest','so good','so great', 'not good', 'not bad', 'really great','really bad', 'really good', \"very good\", \n",
    "          'not impressed','very impressive', 'well made', 'badly made', 'not great', 'too big', 'too small', \n",
    "          'very poor', 'not working','working good', \"doesn't work\", \"didn't work\", \"doesn't fit\", \n",
    "          \"wouldn't recommend\", 'would recommend', 'not nice', 'not working','not easy', 'not happy']\n",
    "\n",
    "unigram = ['problem','broken','good', 'great', 'garbage', 'junk', 'disappointed', 'love', 'not', 'ugly', 'beautiful', \n",
    "           'pleased', 'very', 'waste','flaw', \"doesn't\", 'avoid', 'back', 'fast', 'slow', 'useless', 'useful', \n",
    "           'quality', 'well', 'beware', 'recommend', 'nice','quality', 'cool', 'satisfied', 'easy', 'fine', \n",
    "           'never', 'negative', 'lose', 'awful', 'lousy', 'unsatisfactory','satisfactory', 'mistake', 'happy', \n",
    "           'sad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Created new single word list (unigram) and double word list (bigram)\n",
    "\n",
    "* Let's create the first model using unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model using Unigram ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in unigram:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    s1_df[str(word)] = s1_df.review.str.contains(\n",
    "       str(word) ,\n",
    "        case=False\n",
    "    )\n",
    "# ' ' + str(word) + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>problem</th>\n",
       "      <th>broken</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>garbage</th>\n",
       "      <th>junk</th>\n",
       "      <th>disappointed</th>\n",
       "      <th>love</th>\n",
       "      <th>...</th>\n",
       "      <th>never</th>\n",
       "      <th>negative</th>\n",
       "      <th>lose</th>\n",
       "      <th>awful</th>\n",
       "      <th>lousy</th>\n",
       "      <th>unsatisfactory</th>\n",
       "      <th>satisfactory</th>\n",
       "      <th>mistake</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  problem  \\\n",
       "0  So there is no way for me to plug it in here i...          0    False   \n",
       "1                        Good case, Excellent value.          1    False   \n",
       "2                             Great for the jawbone.          1    False   \n",
       "3  Tied to charger for conversations lasting more...          0     True   \n",
       "4                                  The mic is great.          1    False   \n",
       "\n",
       "   broken   good  great  garbage   junk  disappointed   love  ...    never  \\\n",
       "0   False  False  False    False  False         False  False  ...    False   \n",
       "1   False   True  False    False  False         False  False  ...    False   \n",
       "2   False  False   True    False  False         False  False  ...    False   \n",
       "3   False  False  False    False  False         False  False  ...    False   \n",
       "4   False  False   True    False  False         False  False  ...    False   \n",
       "\n",
       "   negative   lose  awful  lousy  unsatisfactory  satisfactory  mistake  \\\n",
       "0     False  False  False  False           False         False    False   \n",
       "1     False  False  False  False           False         False    False   \n",
       "2     False  False  False  False           False         False    False   \n",
       "3     False  False  False  False           False         False    False   \n",
       "4     False  False  False  False           False         False    False   \n",
       "\n",
       "   happy    sad  \n",
       "0  False  False  \n",
       "1  False  False  \n",
       "2  False  False  \n",
       "3  False  False  \n",
       "4  False  False  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = s1_df[unigram]\n",
    "target1 = s1_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 243\n",
      "Accuracy = 75.70%\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb1 = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb1.fit(data1, target1)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred1 = bnb1.predict(data1)\n",
    "\n",
    "num_data = data1.shape[0]\n",
    "correct = (num_data - (target1 != y_pred1).sum())/num_data * 100\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data1.shape[0],\n",
    "    (target1 != y_pred1).sum()\n",
    "))\n",
    "\n",
    "print(\"Accuracy = {:.2f}%\".format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78  0.75  0.765 0.74  0.715]\n",
      "cv average is = 75.00%\n"
     ]
    }
   ],
   "source": [
    "cvout1 = cross_val_score(bnb1, data1, target1, cv=5)\n",
    "print(cvout1)\n",
    "print(\"cv average is = {:.2f}%\".format(cvout1.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[441  59]\n",
      " [184 316]]\n",
      "True Positive = 31.60%\n",
      "False Positive = 5.90%\n",
      "True Negative = 44.10%\n",
      "False Negative = 18.40%\n",
      "sensitivity or hit rate is 63.20%\n",
      "specificity or True Negative rate is 88.20%\n"
     ]
    }
   ],
   "source": [
    "cm1 = confusion_matrix(target1, y_pred1)\n",
    "print(cm1)\n",
    "print(\"True Positive = {:.2f}%\".format(cm1[1,1]/10))\n",
    "print(\"False Positive = {:.2f}%\".format(cm1[0,1]/10))\n",
    "print(\"True Negative = {:.2f}%\".format(cm1[0,0]/10))\n",
    "print(\"False Negative = {:.2f}%\".format(cm1[1,0]/10))\n",
    "print(\"sensitivity or hit rate is {:.2f}%\".format(cm1[1,1]/(cm1[1,0]+cm1[1,1])*100))\n",
    "# sensitivity (recall) is the percentage of positives identified or TP/FN+TP\n",
    "print(\"specificity or True Negative rate is {:.2f}%\".format(cm1[0,0]/(cm1[0,0]+cm1[0,1])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model using Bigram ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_df = sentiment_raw.copy() # make the second copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bigram:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    s2_df[str(word)] = s2_df.review.str.contains(\n",
    "       str(word) ,\n",
    "        case=False\n",
    "    )\n",
    "# ' ' + str(word) + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = s2_df[bigram]\n",
    "target2 = s2_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 457\n",
      "Accuracy = 54.30%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb2 = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb2.fit(data2, target2)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred2 = bnb2.predict(data2)\n",
    "\n",
    "num_data = data2.shape[0]\n",
    "correct = (num_data - (target2 != y_pred2).sum())/num_data * 100\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data2.shape[0],\n",
    "    (target2 != y_pred2).sum()\n",
    "))\n",
    "\n",
    "print(\"Accuracy = {:.2f}%\".format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55  0.53  0.545 0.54  0.53 ]\n",
      "cv average is = 53.90%\n"
     ]
    }
   ],
   "source": [
    "cvout2 = cross_val_score(bnb2, data2, target2, cv=5)\n",
    "print(cvout2)\n",
    "print(\"cv average is = {:.2f}%\".format(cvout2.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[498   2]\n",
      " [455  45]]\n",
      "True Positive = 4.50%\n",
      "False Positive = 0.20%\n",
      "True Negative = 49.80%\n",
      "False Negative = 45.50%\n",
      "sensitivity or hit rate is 9.00%\n",
      "specificity or True Negative rate is 99.60%\n"
     ]
    }
   ],
   "source": [
    "cm2 = confusion_matrix(target2, y_pred2)\n",
    "print(cm2)\n",
    "print(\"True Positive = {:.2f}%\".format(cm2[1,1]/10))\n",
    "print(\"False Positive = {:.2f}%\".format(cm2[0,1]/10))\n",
    "print(\"True Negative = {:.2f}%\".format(cm2[0,0]/10))\n",
    "print(\"False Negative = {:.2f}%\".format(cm2[1,0]/10))\n",
    "print(\"sensitivity or hit rate is {:.2f}%\".format(cm2[1,1]/(cm2[1,0]+cm2[1,1])*100))\n",
    "# sensitivity (recall) is the percentage of positives identified or TP/FN+TP\n",
    "print(\"specificity or True Negative rate is {:.2f}%\".format(cm2[0,0]/(cm2[0,0]+cm2[0,1])*100))\n",
    "# percentage of negatives identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Model using Unigram with Bigram ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_df = sentiment_raw.copy() # make the third copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bigram:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    s3_df[str(word)] = s3_df.review.str.contains(\n",
    "       str(word) ,\n",
    "        case=False\n",
    "    )\n",
    "    \n",
    "for word in unigram:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    s3_df[str(word)] = s3_df.review.str.contains(\n",
    "       str(word) ,\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = s3_df[unigram + bigram]\n",
    "target3 = s3_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 226\n",
      "Accuracy = 77.40%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate our model and store it in a new variable.\n",
    "bnb3 = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb3.fit(data3, target3)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred3 = bnb3.predict(data3)\n",
    "\n",
    "num_data = data3.shape[0]\n",
    "correct = (num_data - (target3 != y_pred3).sum())/num_data * 100\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data3.shape[0],\n",
    "    (target3 != y_pred3).sum()\n",
    "))\n",
    "\n",
    "print(\"Accuracy = {:.2f}%\".format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.795 0.765 0.785 0.76  0.72 ]\n",
      "cv average is = 76.50%\n"
     ]
    }
   ],
   "source": [
    "cvout3 = cross_val_score(bnb3, data3, target3, cv=5)\n",
    "print(cvout3)\n",
    "print(\"cv average is = {:.2f}%\".format(cvout3.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[443  57]\n",
      " [169 331]]\n",
      "True Positive = 33.10%\n",
      "False Positive = 5.70%\n",
      "True Negative = 44.30%\n",
      "False Negative = 16.90%\n",
      "sensitivity or hit rate is 66.20%\n",
      "specificity or True Negative rate is 88.60%\n"
     ]
    }
   ],
   "source": [
    "cm3 = confusion_matrix(target3, y_pred3)\n",
    "print(cm3)\n",
    "print(\"True Positive = {:.2f}%\".format(cm3[1,1]/10))\n",
    "print(\"False Positive = {:.2f}%\".format(cm3[0,1]/10))\n",
    "print(\"True Negative = {:.2f}%\".format(cm3[0,0]/10))\n",
    "print(\"False Negative = {:.2f}%\".format(cm3[1,0]/10))\n",
    "print(\"sensitivity or hit rate is {:.2f}%\".format(cm3[1,1]/(cm3[1,0]+cm3[1,1])*100))\n",
    "# sensitivity (recall) is the percentage of positives identified or TP/FN+TP\n",
    "print(\"specificity or True Negative rate is {:.2f}%\".format(cm3[0,0]/(cm3[0,0]+cm3[0,1])*100))\n",
    "# percentage of negatives identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Model with Unigrams and Multinomial Naive Bayes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4_df = sentiment_raw.copy() # make the fourt copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in unigram:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    s4_df[str(word)] = s4_df.review.str.count(\n",
    "       str(word) ,\n",
    "        flags=re.IGNORECASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>problem</th>\n",
       "      <th>broken</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>garbage</th>\n",
       "      <th>junk</th>\n",
       "      <th>disappointed</th>\n",
       "      <th>love</th>\n",
       "      <th>...</th>\n",
       "      <th>never</th>\n",
       "      <th>negative</th>\n",
       "      <th>lose</th>\n",
       "      <th>awful</th>\n",
       "      <th>lousy</th>\n",
       "      <th>unsatisfactory</th>\n",
       "      <th>satisfactory</th>\n",
       "      <th>mistake</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  problem  \\\n",
       "0  So there is no way for me to plug it in here i...          0        0   \n",
       "1                        Good case, Excellent value.          1        0   \n",
       "2                             Great for the jawbone.          1        0   \n",
       "3  Tied to charger for conversations lasting more...          0        1   \n",
       "4                                  The mic is great.          1        0   \n",
       "\n",
       "   broken  good  great  garbage  junk  disappointed  love ...   never  \\\n",
       "0       0     0      0        0     0             0     0 ...       0   \n",
       "1       0     1      0        0     0             0     0 ...       0   \n",
       "2       0     0      1        0     0             0     0 ...       0   \n",
       "3       0     0      0        0     0             0     0 ...       0   \n",
       "4       0     0      1        0     0             0     0 ...       0   \n",
       "\n",
       "   negative  lose  awful  lousy  unsatisfactory  satisfactory  mistake  happy  \\\n",
       "0         0     0      0      0               0             0        0      0   \n",
       "1         0     0      0      0               0             0        0      0   \n",
       "2         0     0      0      0               0             0        0      0   \n",
       "3         0     0      0      0               0             0        0      0   \n",
       "4         0     0      0      0               0             0        0      0   \n",
       "\n",
       "   sad  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = s4_df[unigram]\n",
    "target4 = s4_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 242\n",
      "Accuracy = 75.80%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate our model and store it in a new variable.\n",
    "bnb4 = MultinomialNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb4.fit(data4, target4)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred4 = bnb4.predict(data4)\n",
    "\n",
    "num_data = data4.shape[0]\n",
    "correct = (num_data - (target4 != y_pred4).sum())/num_data * 100\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data4.shape[0],\n",
    "    (target4 != y_pred4).sum()\n",
    "))\n",
    "\n",
    "print(\"Accuracy = {:.2f}%\".format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.775 0.755 0.765 0.725 0.715]\n",
      "cv average is = 74.70%\n"
     ]
    }
   ],
   "source": [
    "cvout4 = cross_val_score(bnb4, data4, target4, cv=5)\n",
    "print(cvout4)\n",
    "print(\"cv average is = {:.2f}%\".format(cvout4.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[443  57]\n",
      " [185 315]]\n",
      "True Positive = 31.50%\n",
      "False Positive = 5.70%\n",
      "True Negative = 44.30%\n",
      "False Negative = 18.50%\n",
      "sensitivity or hit rate is 63.00%\n",
      "specificity or True Negative rate is 88.60%\n"
     ]
    }
   ],
   "source": [
    "cm4 = confusion_matrix(target4, y_pred4)\n",
    "print(cm4)\n",
    "print(\"True Positive = {:.2f}%\".format(cm4[1,1]/10))\n",
    "print(\"False Positive = {:.2f}%\".format(cm4[0,1]/10))\n",
    "print(\"True Negative = {:.2f}%\".format(cm4[0,0]/10))\n",
    "print(\"False Negative = {:.2f}%\".format(cm4[1,0]/10))\n",
    "print(\"sensitivity or hit rate is {:.2f}%\".format(cm4[1,1]/(cm4[1,0]+cm4[1,1])*100))\n",
    "# sensitivity (recall) is the percentage of positives identified or TP/FN+TP\n",
    "print(\"specificity or True Negative rate is {:.2f}%\".format(cm4[0,0]/(cm4[0,0]+cm4[0,1])*100))\n",
    "# percentage of negatives identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Model using both Unigram and Bigram using Multinomial Bayes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5_df = sentiment_raw.copy() # make the fifth copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in unigram:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    s5_df[str(word)] = s5_df.review.str.count(\n",
    "       str(word) ,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "for word in bigram:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    s5_df[str(word)] = s5_df.review.str.count(\n",
    "       str(word) ,\n",
    "        flags=re.IGNORECASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = s5_df[unigram + bigram]\n",
    "target5 = s5_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 222\n",
      "Accuracy = 77.80%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate our model and store it in a new variable.\n",
    "bnb5 = MultinomialNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb5.fit(data5, target5)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred5 = bnb5.predict(data5)\n",
    "\n",
    "num_data = data5.shape[0]\n",
    "correct = (num_data - (target5 != y_pred5).sum())/num_data * 100\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data5.shape[0],\n",
    "    (target5 != y_pred5).sum()\n",
    "))\n",
    "\n",
    "print(\"Accuracy = {:.2f}%\".format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79  0.765 0.785 0.74  0.73 ]\n",
      "cv average is = 76.20%\n"
     ]
    }
   ],
   "source": [
    "cvout5 = cross_val_score(bnb5, data5, target5, cv=5)\n",
    "print(cvout5)\n",
    "print(\"cv average is = {:.2f}%\".format(cvout5.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[448  52]\n",
      " [170 330]]\n",
      "True Positive = 33.00%\n",
      "False Positive = 5.20%\n",
      "True Negative = 44.80%\n",
      "False Negative = 17.00%\n",
      "sensitivity or hit rate is 66.00%\n",
      "specificity or True Negative rate is 89.60%\n"
     ]
    }
   ],
   "source": [
    "cm5 = confusion_matrix(target5, y_pred5)\n",
    "print(cm5)\n",
    "print(\"True Positive = {:.2f}%\".format(cm5[1,1]/10))\n",
    "print(\"False Positive = {:.2f}%\".format(cm5[0,1]/10))\n",
    "print(\"True Negative = {:.2f}%\".format(cm5[0,0]/10))\n",
    "print(\"False Negative = {:.2f}%\".format(cm5[1,0]/10))\n",
    "print(\"sensitivity or hit rate is {:.2f}%\".format(cm5[1,1]/(cm5[1,0]+cm5[1,1])*100))\n",
    "# sensitivity (recall) is the percentage of positives identified or TP/FN+TP\n",
    "print(\"specificity or True Negative rate is {:.2f}%\".format(cm5[0,0]/(cm5[0,0]+cm5[0,1])*100))\n",
    "# percentage of negatives identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Naive Bayes models do not easily suffer from Overfit\n",
    "\n",
    "* Models will probably continue to improve with longer lists of words (Unigrams and Bigrams).\n",
    "\n",
    "* Best model by a slim margin is model 5 (Unigrams + Bigrams with Multinomial NB).\n",
    "\n",
    "* Multinomial NB model only slightly improves results\n",
    "\n",
    "* Bigram NB model (model2) has extremely high True Negative Rate but low hit rate.\n",
    "\n",
    "* We should probably vote model2 with model 5 for even better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
